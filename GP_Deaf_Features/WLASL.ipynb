{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WLASL.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1L2sC7nyvMlav0AeJA9iZoZEkE09dJKpF","authorship_tag":"ABX9TyO24ErIYPg0LFGDY3a2fMaU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QCPLuViALQ3D"},"source":["#**IMPLEMENTATION OF WLASL PAPER**"]},{"cell_type":"markdown","metadata":{"id":"bMC7zfeDLK8b"},"source":["**Some Imports**"]},{"cell_type":"code","metadata":{"id":"W5E3wZV9xXad"},"source":["import os \n","import numpy as np\n","import cv2\n","import math\n","import shutil\n","import random\n","import json\n","import tensorflow as tf\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv3D\n","from tensorflow.keras.layers import MaxPooling3D\n","from tensorflow.keras.layers import AveragePooling3D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Reshape\n","from tensorflow.keras.layers import Lambda\n","# from tensorflow.keras.utils.data_utils import get_file\n","from tensorflow.keras import backend as K\n","from tensorflow.python.ops.distributions.uniform import Uniform\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiC__hot3dcO","executionInfo":{"status":"ok","timestamp":1623610243054,"user_tz":-120,"elapsed":462,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"}},"outputId":"6668d668-f15d-4016-b239-e62f5eb8755c"},"source":["%cd /content/drive/MyDrive/WLASL/code/I3D/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/WLASL/code/I3D\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6uI7XsjZLnl6"},"source":["**Downloading and Preprocessing Of Dataset**"]},{"cell_type":"code","metadata":{"id":"GxMjtR-63JOH"},"source":["!git clone https://github.com/dxli94/WLASL\n","!pip install youtube-dl "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rlFKsbY30NP","executionInfo":{"elapsed":278,"status":"ok","timestamp":1622541991007,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"},"user_tz":-120},"outputId":"7c90d401-a9d1-4e49-be51-de25ad514a6f"},"source":["!python video_downloader.py\n","!python preprocess.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/WLASL/start_kit\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KvFGNPW0L8Ek"},"source":["Check The Number Of Videos"]},{"cell_type":"code","metadata":{"id":"KgyVD1ZdfPbM"},"source":["print(len(os.listdir(\"raw_videos/\")))\n","print(len(os.listdir(\"raw_videos_mp4/\")))\n","print(len(os.listdir(\"videos/\")))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dbtjx98XIyW-"},"source":["**Split WLASL 100 words into Train ,Valid ,Test**\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LsvdQlMJS6I","executionInfo":{"elapsed":8,"status":"ok","timestamp":1622661272262,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"},"user_tz":-120},"outputId":"02f1d543-57d5-44f6-fa40-d9a4a254878f"},"source":["%cd /content/drive/MyDrive/WLASL/data100/\n","!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/WLASL/data100\n","/content/drive/MyDrive/WLASL/data100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8nadQuS4M63o"},"source":["content = json.load(open('/content/drive/MyDrive/WLASL/code/I3D/preprocess/nslt_100.json'))\n","\n","\n","if not os.path.exists('train'):\n","    os.mkdir('train')\n","if not os.path.exists('val'):\n","    os.mkdir('val')\n","if not os.path.exists('test'):\n","    os.mkdir('test')\n","\n","for key,value in content.items():\n","    mode = value['subset']\n","    video_id=key\n","    label = str(value['action'][0])\n","    # print(mode , video_id , label)\n","    if not os.path.exists(os.path.join(mode,label)):\n","        os.mkdir(os.path.join(mode,label))\n","    src = os.path.join('/content/drive/MyDrive/WLASL/start_kit/videos',video_id +'.mp4')\n","    dest = os.path.join(mode,label,video_id +'.mp4')\n","    if os.path.exists(dest):\n","        continue\n","    if not os.path.exists(src):\n","        continue\n","    # crop_video_file(instance['bbox'],os.path.join(root,src),os.path.join(root,dest),video_id +'.mp4')\n","    shutil.copy(src,dest)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LrL3vpVZO2ma"},"source":["Check if data100 is complete"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wc3_J-98Ka0F","executionInfo":{"elapsed":542,"status":"ok","timestamp":1622908962446,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"},"user_tz":-120},"outputId":"e6fbb7db-c80f-447c-c5c0-5552c34c729b"},"source":["count=0\n","data_path='/content/drive/MyDrive/WLASL/data100'\n","folders = os.listdir(data_path)\n","for folder in folders:\n","  folder_mode = os.listdir(os.path.join(data_path,folder))\n","  for folder_class in folder_mode:\n","    num_of_videos = len(os.listdir(os.path.join(data_path,folder,folder_class)))\n","    count = count + num_of_videos\n","print(count)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1797\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Avx4l7WP9hm","executionInfo":{"elapsed":328,"status":"ok","timestamp":1622663027066,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"},"user_tz":-120},"outputId":"8f566c7c-fb93-44bd-fe63-ca72fe52adbd"},"source":["content = json.load(open('/content/drive/MyDrive/WLASL/code/I3D/preprocess/nslt_100.json'))\n","len(content)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2038"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"YYxFLjOPQamT"},"source":["**Split WLASL 2000 words into Train ,Valid ,Test**\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYF0qbxNQsmr","executionInfo":{"elapsed":311,"status":"ok","timestamp":1622663159735,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"},"user_tz":-120},"outputId":"2ef5a860-2325-4e9b-db82-65f5003dc56e"},"source":["%cd /content/drive/MyDrive/WLASL/data2000/\n","!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/WLASL/data2000\n","/content/drive/MyDrive/WLASL/data2000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1NcXki64QNau"},"source":["content = json.load(open('/content/drive/MyDrive/WLASL/code/I3D/preprocess/nslt_2000.json'))\n","\n","\n","if not os.path.exists('train'):\n","    os.mkdir('train')\n","if not os.path.exists('val'):\n","    os.mkdir('val')\n","if not os.path.exists('test'):\n","    os.mkdir('test')\n","\n","for key,value in content.items():\n","    mode = value['subset']\n","    video_id=key\n","    label = str(value['action'][0])\n","    # print(mode , video_id , label)\n","    if not os.path.exists(os.path.join(mode,label)):\n","        os.mkdir(os.path.join(mode,label))\n","    src = os.path.join('/content/drive/MyDrive/WLASL/start_kit/videos',video_id +'.mp4')\n","    dest = os.path.join(mode,label,video_id +'.mp4')\n","    if os.path.exists(dest):\n","        continue\n","    if not os.path.exists(src):\n","        continue\n","    # crop_video_file(instance['bbox'],os.path.join(root,src),os.path.join(root,dest),video_id +'.mp4')\n","    shutil.copy(src,dest)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Wc1gdcGTniL"},"source":["\n","\n","Check if data2000 is complete"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDmxUYzyQwXr","executionInfo":{"elapsed":3216,"status":"ok","timestamp":1622668225589,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"},"user_tz":-120},"outputId":"66b4fa33-8c46-4e12-a9c9-cb51db43b604"},"source":["count=0\n","data_path='/content/drive/MyDrive/WLASL/data2000'\n","folders = os.listdir(data_path)\n","for folder in folders:\n","  folder_mode = os.listdir(os.path.join(data_path,folder))\n","  for folder_class in folder_mode:\n","    num_of_videos = len(os.listdir(os.path.join(data_path,folder,folder_class)))\n","    count = count + num_of_videos\n","print(count)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["19049\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOuqoESbTsuJ","executionInfo":{"elapsed":9,"status":"ok","timestamp":1622668225591,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"},"user_tz":-120},"outputId":"deab1c2e-3f3f-4859-c16a-e7b4f85d8b79"},"source":["content = json.load(open('/content/drive/MyDrive/WLASL/code/I3D/preprocess/nslt_2000.json'))\n","len(content)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21095"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"N57mJynrnqPQ"},"source":["##**Convert WLASL 100 Words To Frames data100_frames**\n","\n","if you will load data as videos using generator , skip this part!"]},{"cell_type":"code","metadata":{"id":"o-Z-LabBqZ8I"},"source":["# path = 'data100_frames/train/'\n","# for i in range(100):\n","#   os.mkdir(path+str(i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZBMQEZuLkSG"},"source":["# path = 'data100_frames/val/'\n","# for i in range(100):\n","#   os.mkdir(path+str(i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jznj7zrWLkDv"},"source":["# path = 'data100_frames/test/'\n","# for i in range(100):\n","#   os.mkdir(path+str(i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5PnIFwhq4nt"},"source":["def video_to_frames(video_path, size=(256,256)):\n","  \"\"\"\n","  video_path -> str, path to video.\n","  size -> (int, int), width, height.\n","  \"\"\"\n","\n","  cap = cv2.VideoCapture(video_path)\n","  frames = []\n","  \n","  while True:\n","      ret, frame = cap.read()\n","  \n","      if ret:\n","          if size:\n","              frame = cv2.resize(frame, size)\n","          frames.append(frame)\n","      else:\n","          break\n","\n","  cap.release()\n","  return np.array(frames)\n","\n","def random_crop(frames,out_size=(224,224)):\n","  t,h,w,c = frames.shape\n","  th,tw = out_size\n","  if w == tw and h == th :\n","      i , j = 0 , 0\n","  else:\n","      i = random.randint(0,(h-th)) if h != th else 0\n","      j = random.randint(0,(w-tw)) if w != tw else 0\n","  \n","  return frames[:, i:i+th, j:j+tw, :] \n","\n","def center_crop(frames,out_size=(224,224)):\n","  t,h,w,c = frames.shape\n","  th,tw = out_size\n","  i = int(np.round((h - th) / 2.))\n","  j = int(np.round((w - tw) / 2.))\n","  return imgs[:, i:i+th, j:j+tw, :]\n","\n","def load_rgb_frames_from_video(video_path, start, num, resize=(256, 256)):\n","\n","  \n","  vidcap = cv2.VideoCapture(video_path)\n","\n","  frames = []\n","\n","  total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n","\n","  vidcap.set(cv2.CAP_PROP_POS_FRAMES, start)\n","  for offset in range(min(num, int(total_frames - start))):\n","      success, img = vidcap.read()\n","      if success:\n","        w, h, c = img.shape\n","        if w < 226 or h < 226:\n","            d = 226. - min(w, h)\n","            sc = 1 + d / min(w, h)\n","            img = cv2.resize(img, dsize=(0, 0), fx=sc, fy=sc)\n","\n","        if w > 256 or h > 256:\n","            img = cv2.resize(img, (math.ceil(w * (256 / w)), math.ceil(h * (256 / h))))\n","\n","        # img = (img / 255.) * 2 - 1\n","\n","        frames.append(img)\n","  return np.array(frames)\n","def make_dataset(split_file, video_path, mode,vid):\n","  '''\n","  split file : path of nslt_100.json\n","  mode : flow or rgb\n","  num_classes : should be for now 100\n","  '''\n","  \n","  with open(split_file, 'r') as f:\n","      data = json.load(f)\n","\n","  count_skipping = 0\n","  \n","\n","  src = 0\n","\n","  if not os.path.exists(video_path):\n","      return ()\n","\n","  num_frames = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","  if mode == 'flow':\n","      num_frames = num_frames // 2\n","\n","  if num_frames - 0 < 9:\n","      print(\"Skip video \", vid)\n","      count_skipping += 1\n","      return ()\n","\n","  # label = np.zeros((num_classes, num_frames), np.float32)\n","\n","  # for l in range(num_frames):\n","  #     c_ = data[vid]['action'][0]\n","  #     label[c_][l] = 1\n","  if count_skipping :\n","      print(\"skipped\")\n","\n","  if len(vid) == 5:\n","      return (vid, src, 0, data[vid]['action'][2] - data[vid]['action'][1])\n","  elif len(vid) == 6:  ## sign kws instances\n","      return (vid, src, data[vid]['action'][1], data[vid]['action'][2] - data[vid]['action'][1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hVB1xRakJPo2"},"source":["**(Train)**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WmEELbQAy_yO","executionInfo":{"elapsed":1164818,"status":"ok","timestamp":1622984025742,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"},"user_tz":-120},"outputId":"efa6c5c3-0248-4d7a-ecdb-ceb5731a1133"},"source":["split_file = \"code/I3D/preprocess/nslt_100.json\"\n","mode = \"rgb\"\n","paths = \"data100/train/\"\n","dest = \"data100_frames/train/\"\n","folders = os.listdir(paths)   \n","for folder in folders:\n","    videos = os.listdir(os.path.join(paths,folder))\n","    for video in videos:\n","        video_path = os.path.join(paths,folder,video)\n","        vid = video[:-4]\n","        info  = make_dataset(split_file , video_path, mode , vid)\n","        if info:\n","            vid, src, start_frame , nf = info\n","            total_frames = 64\n","\n","            try:\n","                start_f = random.randint(0, nf - total_frames - 1) + start_frame\n","            except ValueError:\n","                start_f = start_frame\n","\n","            imgs = load_rgb_frames_from_video(video_path, start_f, total_frames)\n","            frames = random_crop(imgs)\n","            count = 0\n","            if not os.path.exists(os.path.join(dest,folder,vid)):\n","              os.mkdir(os.path.join(dest,folder,vid))\n","            for frame in frames:\n","                count +=1\n","                if os.path.exists(os.path.join(dest,folder,vid , '{}.jpg').format(count)):\n","                  # print(os.path.join(dest,folder,vid , '{}.jpg').format(count) + \" already exists\")\n","                  continue\n","                else :\n","                  print(\"Saving\" + os.path.join(dest,folder,vid , '{}.jpg').format(count))\n","                  cv2.imwrite(os.path.join(dest,folder,vid , '{}.jpg').format(count),frame)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Savingdata100_frames/train/55/11775/60.jpg\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4kxwJ0gyJZKN"},"source":["**(Val)**"]},{"cell_type":"code","metadata":{"id":"PmTMSgASE6cw"},"source":["split_file = \"code/I3D/preprocess/nslt_100.json\"\n","mode = \"rgb\"\n","paths = \"data100/val/\"\n","dest = \"data100_frames/val/\"\n","folders = os.listdir(paths)   \n","for folder in folders:\n","    videos = os.listdir(os.path.join(paths,folder))\n","    for video in videos:\n","        video_path = os.path.join(paths,folder,video)\n","        vid = video[:-4]\n","        info  = make_dataset(split_file , video_path, mode , vid)\n","        if info:\n","            vid, src, start_frame , nf = info\n","            total_frames = 64\n","\n","            try:\n","                start_f = random.randint(0, nf - total_frames - 1) + start_frame\n","            except ValueError:\n","                start_f = start_frame\n","\n","            imgs = load_rgb_frames_from_video(video_path, start_f, total_frames)\n","            frames = center_crop(imgs)\n","            count = 0\n","            if not os.path.exists(os.path.join(dest,folder,vid)):\n","              os.mkdir(os.path.join(dest,folder,vid))\n","            for frame in frames:\n","                count +=1\n","                if os.path.exists(os.path.join(dest,folder,vid , '{}.jpg').format(count)):\n","                  #  print(os.path.join(dest,folder,vid , '{}.jpg').format(count) + \" already exists\")\n","                  continue\n","                else :\n","                  print(\"Saving\" + os.path.join(dest,folder,vid , '{}.jpg').format(count))\n","                  cv2.imwrite(os.path.join(dest,folder,vid , '{}.jpg').format(count),frame)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P2D9eAyKLr5r"},"source":["**(Test)**"]},{"cell_type":"code","metadata":{"id":"ExjfzqaiLG0X"},"source":["split_file = \"code/I3D/preprocess/nslt_100.json\"\n","mode = \"rgb\"\n","paths = \"data100/test/\"\n","dest = \"data100_frames/test/\"\n","folders = os.listdir(paths)   \n","for folder in folders:\n","    videos = os.listdir(os.path.join(paths,folder))\n","    for video in videos:\n","        video_path = os.path.join(paths,folder,video)\n","        vid = video[:-4]\n","        info  = make_dataset(split_file , video_path, mode , vid)\n","        if info:\n","            vid, src, start_frame , nf = info\n","            total_frames = 64\n","\n","            try:\n","                start_f = random.randint(0, nf - total_frames - 1) + start_frame\n","            except ValueError:\n","                start_f = start_frame\n","\n","            imgs = load_rgb_frames_from_video(video_path, start_f, total_frames)\n","            frames = center_crop(imgs)\n","            count = 0\n","            if not os.path.exists(os.path.join(dest,folder,vid)):\n","              os.mkdir(os.path.join(dest,folder,vid))\n","            for frame in frames:\n","                count +=1\n","                if os.path.exists(os.path.join(dest,folder,vid , '{}.jpg').format(count)):\n","                  # print(os.path.join(dest,folder,vid , '{}.jpg').format(count) + \" already exists\")\n","                  continue\n","                else :\n","                  print(\"Saving\" + os.path.join(dest,folder,vid , '{}.jpg').format(count))\n","                  cv2.imwrite(os.path.join(dest,folder,vid , '{}.jpg').format(count),frame)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E3FYDuGDM1Hi"},"source":["**Check if data100_frames is completed**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFFnVfdXMFoP","executionInfo":{"elapsed":23,"status":"ok","timestamp":1622984384312,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"},"user_tz":-120},"outputId":"9750d664-2233-4a30-f7bd-9ff3f0e2097b"},"source":["count=0\n","data_path='/content/drive/MyDrive/WLASL/data100_frames'\n","folders = os.listdir(data_path)\n","for folder in folders:\n","  folder_mode = os.listdir(os.path.join(data_path,folder))\n","  for folder_class in folder_mode:\n","    num_of_videos = len(os.listdir(os.path.join(data_path,folder,folder_class)))\n","    count = count + num_of_videos\n","print(count)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1797\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ycor02iFerH4"},"source":["**Apply Padding**"]},{"cell_type":"code","metadata":{"id":"9LDsVW2kNEEU"},"source":["def padding(folder_path):\n","    ref_frames = ['1.jpg','2.jpg', '3.jpg' ,'4.jpg','5.jpg', '6.jpg', '7.jpg', '8.jpg', '9.jpg','10.jpg',\n","     '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg','20.jpg',\n","     '21.jpg', '22.jpg', '23.jpg', '24.jpg', '25.jpg', '26.jpg', '27.jpg', '28.jpg', '29.jpg', '30.jpg', \n","     '31.jpg', '32.jpg', '33.jpg', '34.jpg', '35.jpg', '36.jpg', '37.jpg', '38.jpg', '39.jpg','40.jpg', \n","     '41.jpg', '42.jpg', '43.jpg', '44.jpg', '45.jpg', '46.jpg', '47.jpg', '48.jpg', '49.jpg', '50.jpg', \n","     '51.jpg', '52.jpg', '53.jpg', '54.jpg', '55.jpg', '56.jpg', '57.jpg', '58.jpg', '59.jpg', '60.jpg'\n","     '61.jpg' ,'62.jpg' ,'63.jpg' ,'64.jpg']\n","    sorted_frames = []     \n","    frames = os.listdir(folder_path)\n","    for x in ref_frames:\n","        if x in frames:\n","            sorted_frames.append(x)\n","        else:\n","            break\n","    nf = len(sorted_frames)\n","    if nf != 64 :\n","        print(\"Saving at ....\"+folder_path)\n","        num_padding = 64 - nf\n","        prob = np.random.random_sample()\n","        if prob > 0.5:\n","            pad_img = cv2.imread(os.path.join(folder_path,sorted_frames[0]))\n","            pad = np.tile(np.expand_dims(pad_img, axis=0), (num_padding, 1, 1, 1))\n","            \n","        else:\n","            pad_img = cv2.imread(os.path.join(folder_path,sorted_frames[-1]),1)\n","            pad = np.tile(np.expand_dims(pad_img, axis=0), (num_padding, 1, 1, 1))\n","        count = nf + 1\n","        for frame in pad:\n","            # print(\"Saving....\"+os.path.join(folder_path,str(count))+'.jpg')\n","            cv2.imwrite(os.path.join(folder_path,str(count))+'.jpg',frame )\n","            count += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2yiiIYEee0bl"},"source":["**(Train)**"]},{"cell_type":"code","metadata":{"id":"ClD6fXLbe3qt"},"source":["paths = \"data100_frames/train/\"\n","folders = os.listdir(paths)   \n","for folder in folders:\n","  print(folder)\n","  videos = os.listdir(os.path.join(paths,folder))\n","  for video in videos:\n","    video_path = os.path.join(paths,folder,video)\n","    padding(video_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s73x2fgDnGNd"},"source":["**(Val)**"]},{"cell_type":"code","metadata":{"id":"dS3_t-jWk5W2"},"source":["paths = \"data100_frames/val/\"\n","folders = os.listdir(paths)   \n","for folder in folders:\n","  print(folder)\n","  videos = os.listdir(os.path.join(paths,folder))\n","  for video in videos:\n","    video_path = os.path.join(paths,folder,video)\n","    padding(video_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TQeeGJxKnRP1"},"source":["**(Test)**"]},{"cell_type":"code","metadata":{"id":"uof39aD1nOKl"},"source":["paths = \"data100_frames/test/\"\n","folders = os.listdir(paths)   \n","for folder in folders:\n","  print(folder)\n","  videos = os.listdir(os.path.join(paths,folder))\n","  for video in videos:\n","    video_path = os.path.join(paths,folder,video)\n","    padding(video_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R8CFJI-SnaZy"},"source":["**Check all videos are 64 frames**"]},{"cell_type":"code","metadata":{"id":"t7YQM1x0nV-V"},"source":["paths = \"data100_frames/\"\n","modes = os.listdir(paths)\n","for mode in modes:\n","  folders = os.listdir(os.path.join(paths,mode))\n","  for folder in folders:\n","    videos = os.listdir(os.path.join(paths,mode,folder))\n","    for video in videos:\n","      video_path = os.path.join(paths,mode,folder,video)\n","      nf = len(os.listdir(video_path))\n","      if nf != 64:\n","        print('Mode: ' + mode + '......' + 'Class: ' + folder + '......' + 'Video_id: ' + video + '......' 'No. Frames: ' + nf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T1cMaN37dQPx"},"source":["##**Modeling I3D**"]},{"cell_type":"code","metadata":{"id":"unw5_6ZyHpXE"},"source":["WEIGHTS = {\n","    'flow_imagenet_and_kinetics':\n","        'flow_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels.h5',\n","    'flow_imagenet_and_kinetics_no_top':\n","        'flow_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5',\n","    'rgb_imagenet_and_kinetics':\n","        'rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels.h5',\n","    'rgb_imagenet_and_kinetics_no_top':\n","        'rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5',\n","}\n","\n","\n","def Unit_3d(x,\n","            filters,\n","            num_frames,\n","            num_row,\n","            num_col,\n","            padding='same',\n","            strides=(1, 1, 1),\n","            use_bias=False,\n","            use_activation_fn=True,\n","            use_bn=True,\n","            name=None):\n","    \"\"\"\n","    Utility function to apply conv3d + BN.\n","    :return: Output tensor after applying `Conv3D` and `BatchNormalization`.\n","    \"\"\"\n","    if name is not None:\n","        bn_name = name + '_bn'\n","        conv_name = name + '_conv'\n","    else:\n","        bn_name = None\n","        conv_name = None\n","\n","    layer = Conv3D(\n","        filters, (num_frames, num_row, num_col),\n","        strides=strides,\n","        padding=padding,\n","        use_bias=use_bias,\n","        name=conv_name)(x)\n","\n","    if use_bn:\n","        layer = BatchNormalization(axis=4, scale=False, name=bn_name)(layer)\n","\n","    if use_activation_fn:\n","        layer = Activation('relu', name=name)(layer)\n","\n","    return layer\n","\n","\n","def PreTrainedInception3d(include_top=True,\n","                          pretrained_weights='rgb_imagenet_and_kinetics',\n","                          input_shape=None,\n","                          dropout_prob=0.0,\n","                          endpoint_logit=True,\n","                          classes=400):\n","    \"\"\"\n","    Instantiates the Inception i3D Inception v1 architecture.\n","    :return: Inception i3D model model.\n","    \"\"\"\n","    if not include_top:\n","        pretrained_weights = pretrained_weights + '_no_top'\n","\n","    if pretrained_weights not in WEIGHTS:\n","        raise ValueError('in valid weight name')\n","\n","    input_shape = input_shape\n","    img_input = Input(shape=input_shape)\n","    if K.image_data_format() == 'channels_first':\n","        channel_axis = 1\n","    else:\n","        channel_axis = 4\n","\n","    # Downsampling via convolution (spatial and temporal)\n","    x = Unit_3d(img_input, 64, 7, 7, 7, strides=(2, 2, 2), padding='same', name='Conv3d_1a_7x7')\n","\n","    # Downsampling (spatial only)\n","    x = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same', name='MaxPool2d_2a_3x3')(x)\n","    x = Unit_3d(x, 64, 1, 1, 1, strides=(1, 1, 1), padding='same', name='Conv3d_2b_1x1')\n","    x = Unit_3d(x, 192, 3, 3, 3, strides=(1, 1, 1), padding='same', name='Conv3d_2c_3x3')\n","\n","    # Downsampling (spatial only)\n","    x = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same', name='MaxPool2d_3a_3x3')(x)\n","\n","    # Mixed 3b\n","    branch_0 = Unit_3d(x, 64, 1, 1, 1, padding='same', name='Conv3d_3b_0a_1x1')\n","\n","    branch_1 = Unit_3d(x, 96, 1, 1, 1, padding='same', name='Conv3d_3b_1a_1x1')\n","    branch_1 = Unit_3d(branch_1, 128, 3, 3, 3, padding='same', name='Conv3d_3b_1b_3x3')\n","\n","    branch_2 = Unit_3d(x, 16, 1, 1, 1, padding='same', name='Conv3d_3b_2a_1x1')\n","    branch_2 = Unit_3d(branch_2, 32, 3, 3, 3, padding='same', name='Conv3d_3b_2b_3x3')\n","\n","    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_3b_3a_3x3')(x)\n","    branch_3 = Unit_3d(branch_3, 32, 1, 1, 1, padding='same', name='Conv3d_3b_3b_1x1')\n","\n","    x = layers.concatenate(\n","        [branch_0, branch_1, branch_2, branch_3],\n","        axis=channel_axis,\n","        name='Mixed_3b')\n","\n","    # Mixed 3c\n","    branch_0 = Unit_3d(x, 128, 1, 1, 1, padding='same', name='Conv3d_3c_0a_1x1')\n","\n","    branch_1 = Unit_3d(x, 128, 1, 1, 1, padding='same', name='Conv3d_3c_1a_1x1')\n","    branch_1 = Unit_3d(branch_1, 192, 3, 3, 3, padding='same', name='Conv3d_3c_1b_3x3')\n","\n","    branch_2 = Unit_3d(x, 32, 1, 1, 1, padding='same', name='Conv3d_3c_2a_1x1')\n","    branch_2 = Unit_3d(branch_2, 96, 3, 3, 3, padding='same', name='Conv3d_3c_2b_3x3')\n","\n","    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_3c_3a_3x3')(x)\n","    branch_3 = Unit_3d(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_3c_3b_1x1')\n","\n","    x = layers.concatenate(\n","        [branch_0, branch_1, branch_2, branch_3],\n","        axis=channel_axis,\n","        name='Mixed_3c')\n","\n","    # Downsampling (spatial and temporal)\n","    x = MaxPooling3D((3, 3, 3), strides=(2, 2, 2), padding='same', name='MaxPool2d_4a_3x3')(x)\n","\n","    # Mixed 4b\n","    branch_0 = Unit_3d(x, 192, 1, 1, 1, padding='same', name='Conv3d_4b_0a_1x1')\n","\n","    branch_1 = Unit_3d(x, 96, 1, 1, 1, padding='same', name='Conv3d_4b_1a_1x1')\n","    branch_1 = Unit_3d(branch_1, 208, 3, 3, 3, padding='same', name='Conv3d_4b_1b_3x3')\n","\n","    branch_2 = Unit_3d(x, 16, 1, 1, 1, padding='same', name='Conv3d_4b_2a_1x1')\n","    branch_2 = Unit_3d(branch_2, 48, 3, 3, 3, padding='same', name='Conv3d_4b_2b_3x3')\n","\n","    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4b_3a_3x3')(x)\n","    branch_3 = Unit_3d(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4b_3b_1x1')\n","\n","    x = layers.concatenate(\n","        [branch_0, branch_1, branch_2, branch_3],\n","        axis=channel_axis,\n","        name='Mixed_4b')\n","\n","    # Mixed 4c\n","    branch_0 = Unit_3d(x, 160, 1, 1, 1, padding='same', name='Conv3d_4c_0a_1x1')\n","\n","    branch_1 = Unit_3d(x, 112, 1, 1, 1, padding='same', name='Conv3d_4c_1a_1x1')\n","    branch_1 = Unit_3d(branch_1, 224, 3, 3, 3, padding='same', name='Conv3d_4c_1b_3x3')\n","\n","    branch_2 = Unit_3d(x, 24, 1, 1, 1, padding='same', name='Conv3d_4c_2a_1x1')\n","    branch_2 = Unit_3d(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4c_2b_3x3')\n","\n","    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4c_3a_3x3')(x)\n","    branch_3 = Unit_3d(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4c_3b_1x1')\n","\n","    x = layers.concatenate(\n","        [branch_0, branch_1, branch_2, branch_3],\n","        axis=channel_axis,\n","        name='Mixed_4c')\n","\n","    # Mixed 4d\n","    branch_0 = Unit_3d(x, 128, 1, 1, 1, padding='same', name='Conv3d_4d_0a_1x1')\n","\n","    branch_1 = Unit_3d(x, 128, 1, 1, 1, padding='same', name='Conv3d_4d_1a_1x1')\n","    branch_1 = Unit_3d(branch_1, 256, 3, 3, 3, padding='same', name='Conv3d_4d_1b_3x3')\n","\n","    branch_2 = Unit_3d(x, 24, 1, 1, 1, padding='same', name='Conv3d_4d_2a_1x1')\n","    branch_2 = Unit_3d(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4d_2b_3x3')\n","\n","    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4d_3a_3x3')(x)\n","    branch_3 = Unit_3d(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4d_3b_1x1')\n","\n","    x = layers.concatenate(\n","        [branch_0, branch_1, branch_2, branch_3],\n","        axis=channel_axis,\n","        name='Mixed_4d')\n","\n","    # Mixed 4e\n","    branch_0 = Unit_3d(x, 112, 1, 1, 1, padding='same', name='Conv3d_4e_0a_1x1')\n","\n","    branch_1 = Unit_3d(x, 144, 1, 1, 1, padding='same', name='Conv3d_4e_1a_1x1')\n","    branch_1 = Unit_3d(branch_1, 288, 3, 3, 3, padding='same', name='Conv3d_4e_1b_3x3')\n","\n","    branch_2 = Unit_3d(x, 32, 1, 1, 1, padding='same', name='Conv3d_4e_2a_1x1')\n","    branch_2 = Unit_3d(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4e_2b_3x3')\n","\n","    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4e_3a_3x3')(x)\n","    branch_3 = Unit_3d(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4e_3b_1x1')\n","\n","    x = layers.concatenate(\n","        [branch_0, branch_1, branch_2, branch_3],\n","        axis=channel_axis,\n","        name='Mixed_4e')\n","\n","    # Mixed 4f\n","    branch_0 = Unit_3d(x, 256, 1, 1, 1, padding='same', name='Conv3d_4f_0a_1x1')\n","\n","    branch_1 = Unit_3d(x, 160, 1, 1, 1, padding='same', name='Conv3d_4f_1a_1x1')\n","    branch_1 = Unit_3d(branch_1, 320, 3, 3, 3, padding='same', name='Conv3d_4f_1b_3x3')\n","\n","    branch_2 = Unit_3d(x, 32, 1, 1, 1, padding='same', name='Conv3d_4f_2a_1x1')\n","    branch_2 = Unit_3d(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_4f_2b_3x3')\n","\n","    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4f_3a_3x3')(x)\n","    branch_3 = Unit_3d(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_4f_3b_1x1')\n","\n","    x = layers.concatenate(\n","        [branch_0, branch_1, branch_2, branch_3],\n","        axis=channel_axis,\n","        name='Mixed_4f')\n","\n","    # Downsampling (spatial and temporal)\n","    x = MaxPooling3D((2, 2, 2), strides=(2, 2, 2), padding='same', name='MaxPool2d_5a_2x2')(x)\n","\n","    # Mixed 5b\n","    branch_0 = Unit_3d(x, 256, 1, 1, 1, padding='same', name='Conv3d_5b_0a_1x1')\n","\n","    branch_1 = Unit_3d(x, 160, 1, 1, 1, padding='same', name='Conv3d_5b_1a_1x1')\n","    branch_1 = Unit_3d(branch_1, 320, 3, 3, 3, padding='same', name='Conv3d_5b_1b_3x3')\n","\n","    branch_2 = Unit_3d(x, 32, 1, 1, 1, padding='same', name='Conv3d_5b_2a_1x1')\n","    branch_2 = Unit_3d(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_5b_2b_3x3')\n","\n","    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_5b_3a_3x3')(x)\n","    branch_3 = Unit_3d(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_5b_3b_1x1')\n","\n","    x = layers.concatenate(\n","        [branch_0, branch_1, branch_2, branch_3],\n","        axis=channel_axis,\n","        name='Mixed_5b')\n","\n","    # Mixed 5c\n","    branch_0 = Unit_3d(x, 384, 1, 1, 1, padding='same', name='Conv3d_5c_0a_1x1')\n","\n","    branch_1 = Unit_3d(x, 192, 1, 1, 1, padding='same', name='Conv3d_5c_1a_1x1')\n","    branch_1 = Unit_3d(branch_1, 384, 3, 3, 3, padding='same', name='Conv3d_5c_1b_3x3')\n","\n","    branch_2 = Unit_3d(x, 48, 1, 1, 1, padding='same', name='Conv3d_5c_2a_1x1')\n","    branch_2 = Unit_3d(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_5c_2b_3x3')\n","\n","    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_5c_3a_3x3')(x)\n","    branch_3 = Unit_3d(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_5c_3b_1x1')\n","\n","    x = layers.concatenate(\n","        [branch_0, branch_1, branch_2, branch_3],\n","        axis=channel_axis,\n","        name='Mixed_5c')\n","\n","    if include_top:\n","        # Classification block\n","        x = AveragePooling3D((2, 7, 7), strides=(1, 1, 1), padding='valid', name='global_avg_pool')(x)\n","        x = Dropout(dropout_prob)(x)\n","\n","        x = Unit_3d(x, classes, 1, 1, 1, padding='same',\n","                    use_bias=True, use_activation_fn=False, use_bn=False, name='Conv3d_6a_1x1')\n","\n","        num_frames_remaining = int(x.shape[1])\n","        x = Reshape((num_frames_remaining, classes))(x)\n","\n","        # logits (raw scores for each class)\n","        x = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n","                   output_shape=lambda s: (s[0], s[2]))(x)\n","\n","        if not endpoint_logit:\n","            x = Activation('softmax', name='prediction')(x)\n","    else:\n","        h = int(x.shape[2])\n","        w = int(x.shape[3])\n","        x = AveragePooling3D((2, h, w), strides=(1, 1, 1), padding='valid', name='global_avg_pool')(x)\n","\n","    inputs = img_input\n","    # create model\n","    model = Model(inputs, x, name='i3d_inception')\n","\n","    # load weights\n","    model.load_weights(WEIGHTS[pretrained_weights])\n","    model.trainable = False\n","\n","    return model\n","\n","\n","def TopLayer(input_shape, classes, dropout_prob):\n","    inputs = Input(shape=input_shape, name=\"input\")\n","    x = Dropout(dropout_prob)(inputs)\n","    x = Unit_3d(x, classes, 1, 1, 1, padding='same',\n","                  use_bias=True, use_activation_fn=False, use_bn=False, name='Conv3d_6a_1x1')\n","    num_frames_remaining = int(x.shape[1])\n","    x = Reshape((num_frames_remaining, classes))(x)\n","    x = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n","               output_shape=lambda s: (s[0], s[2]))(x)\n","    x = Activation('softmax', name='prediction')(x)\n","    final_model = Model(inputs=inputs, outputs=x, name=\"i3d_top\")\n","    return final_model\n","\n","\n","def add_top_layer(base_model: Model, classes: int, dropout_prob: float):\n","    top_layer = TopLayer(base_model.output_shape[1:], classes, dropout_prob)\n","    x = base_model.output\n","    predictions = top_layer(x)\n","    new_model = Model(inputs=base_model.input, outputs=predictions, name=\"i3d_with_top\")\n","    return new_model\n","\n","def layers_freeze(model, leave_last=50):\n","    print(\"Freezing %d layers of %d in Model %s\" % (len(model.layers)-leave_last, len(model.layers), model.name))\n","    for layer in model.layers[:-leave_last]:\n","        layer.trainable = False\n","    for layer in model.layers[-leave_last:]:\n","        layer.trainable = True\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lhh01I5gH8Yh"},"source":["def random_crop(frames,out_size=(224,224)):\n","    t,h,w,c = frames.shape\n","    th,tw = out_size\n","    if w == tw and h == th :\n","        i , j = 0 , 0\n","    else:\n","        i = random.randint(0,(h-th)) if h != th else 0\n","        j = random.randint(0,(w-tw)) if w != tw else 0\n","    \n","    return frames[:, i:i+th, j:j+tw, :] \n","\n","\n","def center_crop(frames,out_size=(224,224)):\n","    t,h,w,c = frames.shape\n","    th,tw = out_size\n","    i = int(np.round((h - th) / 2.))\n","    j = int(np.round((w - tw) / 2.))\n","    return frames[:, i:i+th, j:j+tw, :]\n","\n","\n","def load_rgb_frames_from_video(video_path, start, num, resize=(256, 256)):\n","    vidcap = cv2.VideoCapture(video_path)\n","\n","    frames = list()\n","\n","    total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n","\n","    vidcap.set(cv2.CAP_PROP_POS_FRAMES, start)\n","    for offset in range(min(num, int(total_frames - start))):\n","      success, img = vidcap.read()\n","      if success:\n","        w, h, c = img.shape\n","        if w < 226 or h < 226:\n","            d = 226. - min(w, h)\n","            sc = 1 + d / min(w, h)\n","            img = cv2.resize(img, dsize=(0, 0), fx=sc, fy=sc)\n","\n","        if w > 256 or h > 256:\n","            img = cv2.resize(img, (math.ceil(w * (256 / w)), math.ceil(h * (256 / h))))\n","\n","        img = (img / 255.) * 2 - 1\n","        # img = (img / 255.)\n","        frames.append(img)\n","\n","    return np.asarray(frames, dtype=np.float32)\n","\n","\n","def make_dataset(split_file, video_path, mode,vid):\n","  '''\n","  split file : path of nslt_100.json\n","  mode : flow or rgb\n","  num_classes : should be for now 100\n","  '''\n","  \n","  with open(split_file, 'r') as f:\n","      data = json.load(f)\n","\n","  count_skipping = 0\n","  \n","\n","  src = 0\n","\n","  if not os.path.exists(video_path):\n","      return ()\n","\n","  num_frames = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","  if mode == 'flow':\n","      num_frames = num_frames // 2\n","\n","  if num_frames - 0 < 9:\n","      print(\"Skip video \", vid)\n","      count_skipping += 1\n","      return ()\n","\n","  # label = np.zeros((num_classes, num_frames), np.float32)\n","\n","  # for l in range(num_frames):\n","  #     c_ = data[vid]['action'][0]\n","  #     label[c_][l] = 1\n","  if count_skipping :\n","      print(\"skipped\")\n","\n","  if len(vid) == 5:\n","      return (vid, src, 0, data[vid]['action'][2] - data[vid]['action'][1])\n","  elif len(vid) == 6:  ## sign kws instances\n","      return (vid, src, data[vid]['action'][1], data[vid]['action'][2] - data[vid]['action'][1])\n","\n","\n","def padding(imgs,total_frames):\n","    if imgs.shape[0] < total_frames:\n","            num_padding = total_frames - imgs.shape[0]\n","\n","            if num_padding:\n","                prob = np.random.random_sample()\n","                if prob > 0.5:\n","                    pad_img = imgs[0]\n","                    pad = np.tile(np.expand_dims(pad_img, axis=0), (num_padding, 1, 1, 1))\n","                    padded_imgs = np.concatenate([imgs, pad], axis=0)\n","                else:\n","                    pad_img = imgs[-1]\n","                    pad = np.tile(np.expand_dims(pad_img, axis=0), (num_padding, 1, 1, 1))\n","                    padded_imgs = np.concatenate([imgs, pad], axis=0)\n","    else:\n","            padded_imgs = imgs\n","\n","    return padded_imgs\n","\n","\n","\n","\n","def get_classes(num_classes,path):\n","    file = open(path,'r')\n","    all_lines = file.readlines()\n","    lines = all_lines[:num_classes]\n","    classes=list()\n","    for line in lines:\n","        label=line.split()[0]\n","        classes.append(label)\n","    return classes\n","\n","\n","\n","\n","\n","def test_video(video_path):\n","  total_frames = 64\n","  cap = cv2.VideoCapture(video_path)\n","  nf = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","  print(nf)\n","  start_frame = 0\n","  try:\n","    start_f = random.randint(0, nf - total_frames - 1) + start_frame\n","  except ValueError:\n","    start_f = start_frame\n","  imgs = load_rgb_frames_from_video(video_path, start_f, total_frames)\n","  imgs = padding(imgs , total_frames)\n","  frames = center_crop(imgs)\n","  return frames\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E9Ul6QkUOlh4"},"source":["Check The Number Of Samples in Each Split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RvfzPxbiDL2","executionInfo":{"status":"ok","timestamp":1623440602575,"user_tz":-120,"elapsed":268,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"}},"outputId":"736aa477-e606-4927-f9df-898b007d27cf"},"source":["p = 'data100/'\n","folders = os.listdir(\"data100/\")\n","for folder in folders:\n","  print(folder)\n","  count = 0\n","  classes = os.listdir(os.path.join(p,folder))\n","  for classs in classes:\n","    videos = len(os.listdir(os.path.join(p,folder,classs)))\n","    count += videos\n","\n","  print(count) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["train\n","1264\n","val\n","298\n","test\n","235\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3vIUV6hWspNx"},"source":["def generator_train():\n","      root_dir= 'data100/train/' #directory of the train folder\n","      classes= os.listdir(root_dir)\n","      classes = [int(x) for x in classes]\n","      classes.sort()\n","      classes = [str(x) for x in classes] \n","      no_of_samples_in_each_class = np.array([len(os.listdir(os.path.join(root_dir,classs))) for classs in classes ])\n","      pointer_of_each_class = np.array([0 for _ in classes])\n","      samples_in_each_class= np.array([os.listdir(os.path.join(root_dir,classs)) for classs in classes])\n","      split_file = \"code/I3D/preprocess/nslt_100.json\"\n","      mode = \"rgb\"\n","      while True:\n","        ptr_sum=np.sum(pointer_of_each_class)\n","        samples_sum= np.sum(no_of_samples_in_each_class)\n","        if  ptr_sum == samples_sum: #terminating condition\n","            break\n","\n","        # get random class\n","        while True: # loop until you get a class that has samples left\n","            current_class_indx= np.random.randint(0,len(classes)) # class index\n","\n","            if pointer_of_each_class[current_class_indx] <= no_of_samples_in_each_class[current_class_indx]-1:\n","                break\n","\n","        i = pointer_of_each_class[current_class_indx] # sample index\n","        pointer_of_each_class[current_class_indx]+=1 #increment the pointer\n","\n","        c_name = classes[current_class_indx] # class name\n","        v_name= samples_in_each_class[current_class_indx][i] # video name in class i\n","        video_path = os.path.join(root_dir,c_name,v_name)\n","\n","        # read frames from video ( adjust that to your fast code )\n","        vid = v_name[:-4]\n","        info  = make_dataset(split_file , video_path, mode , vid)\n","        if info:\n","          vid, src, start_frame , nf = info            \n","          total_frames = 64\n","          try:\n","            start_f = random.randint(0, nf - total_frames - 1) + start_frame\n","          except ValueError:\n","            start_f = start_frame\n","          imgs = load_rgb_frames_from_video(video_path, start_f, total_frames)\n","          imgs = padding(imgs , total_frames)\n","          frames = random_crop(imgs)\n","          flip_flag=0\n","          new_frames=[]\n","          if random.random() > 0.5:\n","            flip_flag=1\n","          if flip_flag:\n","            new_frames = np.flip(frames, axis=2).copy()\n","          else:\n","            new_frames = frames\n","        \n","          # yeild the video\n","          yield np.array(new_frames,dtype=np.float32) ,np.array([int(c_name)],dtype=np.int32)\n","\n","def generator_val():\n","    root_dir= 'data100/val/' #directory of the val folder\n","    classes= os.listdir(root_dir)\n","    classes = [int(x) for x in classes]\n","    classes.sort()\n","    classes = [str(x) for x in classes] \n","    no_of_samples_in_each_class = np.array([len(os.listdir(os.path.join(root_dir,classs))) for classs in classes ])\n","    pointer_of_each_class = np.array([0 for _ in classes])\n","    samples_in_each_class= np.array([os.listdir(os.path.join(root_dir,classs)) for classs in classes])\n","    split_file = \"code/I3D/preprocess/nslt_100.json\"\n","    mode = \"rgb\"\n","    while True:\n","        ptr_sum=np.sum(pointer_of_each_class)\n","        samples_sum= np.sum(no_of_samples_in_each_class)\n","        if  ptr_sum == samples_sum: #terminating condition\n","            break\n","\n","        # get random class\n","        while True: # loop until you get a class that has samples left\n","            current_class_indx= np.random.randint(0,len(classes)) # class index\n","\n","            if pointer_of_each_class[current_class_indx] <= no_of_samples_in_each_class[current_class_indx]-1:\n","                break\n","\n","        i = pointer_of_each_class[current_class_indx] # sample index\n","        pointer_of_each_class[current_class_indx]+=1 #increment the pointer\n","\n","        c_name = classes[current_class_indx] # class name\n","        v_name= samples_in_each_class[current_class_indx][i] # video name in class i\n","        video_path = os.path.join(root_dir,c_name,v_name)\n","\n","        # read frames from video ( adjust that to your fast code )\n","        vid = v_name[:-4]\n","        info  = make_dataset(split_file , video_path, mode , vid)\n","        if info:\n","          vid, src, start_frame , nf = info            \n","          total_frames = 64\n","          try:\n","            start_f = random.randint(0, nf - total_frames - 1) + start_frame\n","          except ValueError:\n","            start_f = start_frame\n","          imgs = load_rgb_frames_from_video(video_path, start_f, total_frames)\n","          imgs = padding(imgs , total_frames)\n","          frames = center_crop(imgs)\n","          # yeild the video\n","          yield np.array(frames,dtype=np.float32) ,np.array([int(c_name)],dtype=np.int32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0Sj1eXiIC2W"},"source":["\n","train_gen = tf.data.Dataset.from_generator(generator_train,\n","                                           output_signature=\n","                                           (tf.TensorSpec(shape=(64,224,224,3), dtype=tf.float32),tf.TensorSpec(shape=(1,),dtype=tf.int32)))\n","\n","val_gen = tf.data.Dataset.from_generator(generator_val,\n","                                         output_signature=\n","                                         (tf.TensorSpec(shape=(64,224,224,3), dtype=tf.float32),tf.TensorSpec(shape=(1,),dtype=tf.int32)))\n","\n","\n","train_gen = train_gen.batch(6)\n","val_gen = val_gen.batch(6)\n","EPOCHS = 200"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jDS4ASTPXrd7"},"source":["if os.path.exists(\"/content/drive/MyDrive/WLASL/model/WLASL_drop_05_batch32_freezemodel.hdf5\"):\n","  m_rgb = tf.keras.models.load_model(\"/content/drive/MyDrive/WLASL/model/WLASL_drop_05_batch32_freezemodel.hdf5\")\n","else :\n","  m_rgb = PreTrainedInception3d(include_top=False, pretrained_weights=\"rgb_imagenet_and_kinetics\", dropout_prob=0.5,\n","                        input_shape=(64, 224, 224, 3), classes=400)\n","\n","  # m_rgb = layers_freeze(m_rgb)\n","  # print(\"Freezing layers done\")\n","  m_rgb = add_top_layer(m_rgb, classes=100, dropout_prob=0.5)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-7)\n","m_rgb.compile(optimizer,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False) , metrics=['accuracy'])\n","  # model_ckpts = model_checkpoints()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2EN8U7BOcolS"},"source":["# m_rgb.trainable = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Geq7g3-Sr25"},"source":["m_rgb.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cwLChofFKwzQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be67c03a-1a81-4eb2-a8b5-7a167abfa0ec"},"source":["model_ckpts = tf.keras.callbacks.ModelCheckpoint(filepath=\"/content/drive/MyDrive/WLASL/model/WLASL_drop_05_batch32_freezemodel.hdf5\",monitor='loss',mode=\"min\",verbose=2,save_best_only=True)\n","m_rgb.fit( train_gen  , validation_data=val_gen , batch_size=32 ,verbose=1 ,epochs=EPOCHS ,callbacks=model_ckpts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  if __name__ == '__main__':\n"],"name":"stderr"},{"output_type":"stream","text":["     40/Unknown - 517s 13s/step - loss: 4.7791 - accuracy: 0.0071"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 643s 16s/step - loss: 4.7791 - accuracy: 0.0071 - val_loss: 4.6010 - val_accuracy: 0.0168\n","\n","Epoch 00001: loss improved from inf to 4.77911, saving model to /content/drive/MyDrive/WLASL/model/WLASL_drop_05_batch32_freezemodel.hdf5\n","Epoch 2/200\n","40/40 [==============================] - 613s 15s/step - loss: 4.5538 - accuracy: 0.0285 - val_loss: 4.5280 - val_accuracy: 0.0336\n","\n","Epoch 00002: loss improved from 4.77911 to 4.55385, saving model to /content/drive/MyDrive/WLASL/model/WLASL_drop_05_batch32_freezemodel.hdf5\n","Epoch 3/200\n","40/40 [==============================] - 612s 15s/step - loss: 4.4231 - accuracy: 0.0451 - val_loss: 4.4785 - val_accuracy: 0.0503\n","\n","Epoch 00003: loss improved from 4.55385 to 4.42308, saving model to /content/drive/MyDrive/WLASL/model/WLASL_drop_05_batch32_freezemodel.hdf5\n","Epoch 4/200\n","26/40 [==================>...........] - ETA: 2:53 - loss: 4.2508 - accuracy: 0.0817"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7wWn-LdndA-U"},"source":["##**Loading Pretrained Weights Instead of Training**"]},{"cell_type":"code","metadata":{"id":"q7CPFWRdUxO_"},"source":["def get_classes(num_classes,path):\n","    file = open(path,'r')\n","    all_lines = file.readlines()\n","    lines = all_lines[:num_classes]\n","    classes=list()\n","    for line in lines:\n","        label=line.split()[1]\n","        classes.append(label)\n","    return classes\n","\n","classes = get_classes(100,path=\"/content/drive/MyDrive/WLASL/code/I3D/preprocess/wlasl_class_list.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cz6rRHO4TxS2"},"source":["Install onnx_tf"]},{"cell_type":"code","metadata":{"id":"n0h51gbvT0oR"},"source":["git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow && pip install -e . "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wPaV2ILBRBeU"},"source":["To change the path to ../WLASL/code/I3D/\n","Run the following cell"]},{"cell_type":"code","metadata":{"id":"-m9voyKMRkog"},"source":["%cd ../WLASL/code/I3D"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UdDa3xraQUR3"},"source":["Important Imports"]},{"cell_type":"code","metadata":{"id":"ru3Gz0waQQas"},"source":["import math\n","import os\n","import argparse\n","import torch\n","import sys\n","sys.path\n","sys.path.append('/content/drive/MyDrive/WLASL/onnx-tensorflow/')\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","import onnx\n","from onnx_tf.backend import prepare\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import transforms\n","import videotransforms\n","\n","import numpy as np\n","\n","import torch.nn.functional as F\n","from pytorch_i3d import InceptionI3d\n","\n","# from nslt_dataset_all import NSLT as Dataset\n","from datasets.nslt_dataset_all import NSLT as Dataset\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c5CMVBIRRsIM"},"source":["put the code of this cell in file code get_model.py and put this file in ../WLASL/code/I3D/\n","\n","\n","Then run \n","\n","!python get_model.py"]},{"cell_type":"code","metadata":{"id":"qStFqLsoTKUw"},"source":["import math\n","import os\n","import argparse\n","import torch\n","import sys\n","sys.path\n","sys.path.append('/content/drive/MyDrive/WLASL/onnx-tensorflow/')\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","import onnx\n","from onnx_tf.backend import prepare\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import transforms\n","import videotransforms\n","\n","import numpy as np\n","\n","import torch.nn.functional as F\n","from pytorch_i3d import InceptionI3d\n","\n","# from nslt_dataset_all import NSLT as Dataset\n","from datasets.nslt_dataset_all import NSLT as Dataset\n","import cv2\n","\n","\n","weights = \"/content/drive/MyDrive/WLASL/code/I3D/archived/asl100/FINAL_nslt_100_iters=896_top1=65.89_top5=84.11_top10=89.92.pt\"\n","\n","i3d = InceptionI3d(400, in_channels=3)\n","i3d.load_state_dict(torch.load('weights/rgb_imagenet.pt'))\n","i3d.replace_logits(100)\n","i3d.load_state_dict(torch.load(weights))\n","\n","\n","dummy_input = Variable(torch.randn(1,3,64,224,224))\n","torch.onnx.export(i3d, dummy_input, \"i3d.onnx\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pn7aM8xSUHQy"},"source":[" model = onnx.load('i3d.onnx')\n"," tf_rep = prepare(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dVPhICWsUMkS"},"source":["Loading video sample to test the model"]},{"cell_type":"code","metadata":{"id":"jCYAFXEjdnW-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623551314861,"user_tz":-120,"elapsed":1511,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"}},"outputId":"3d465eb0-3378-42ba-cead-48d5256dd537"},"source":["video = test_video(\"/content/drive/MyDrive/test6.mp4\")\n","video = np.moveaxis(video,-1,0)\n","video.shape\n","print(video.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["101\n","(64, 224, 224, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WqHH8v-s1pvo"},"source":["output = tf_rep.run(np.expand_dims(video,0))\n","result=np.argmax(np.max(np.array(output),axis=-1))\n","classes[result]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xI4K7lICVkf7"},"source":["To Test The Whole Dataset :"]},{"cell_type":"code","metadata":{"id":"XKu1x8hA9b0e"},"source":["def generator_test():\n","    root_dir= '/content/drive/MyDrive/WLASL/data100/test' #directory of the test folder\n","    classes= os.listdir(root_dir)\n","    classes = [int(x) for x in classes]\n","    classes.sort()\n","    classes = [str(x) for x in classes] \n","    no_of_samples_in_each_class = np.array([len(os.listdir(os.path.join(root_dir,classs))) for classs in classes ])\n","    pointer_of_each_class = np.array([0 for _ in classes])\n","    samples_in_each_class= np.array([os.listdir(os.path.join(root_dir,classs)) for classs in classes])\n","    split_file = \"/content/drive/MyDrive/WLASL/code/I3D/preprocess/nslt_100.json\"\n","    mode = \"rgb\"\n","    while True:\n","        ptr_sum=np.sum(pointer_of_each_class)\n","        samples_sum= np.sum(no_of_samples_in_each_class)\n","        if  ptr_sum == samples_sum: #terminating condition\n","            break\n","\n","        # get random class\n","        while True: # loop until you get a class that has samples left\n","            current_class_indx= np.random.randint(0,len(classes)) # class index\n","\n","            if pointer_of_each_class[current_class_indx] <= no_of_samples_in_each_class[current_class_indx]-1:\n","                break\n","\n","        i = pointer_of_each_class[current_class_indx] # sample index\n","        pointer_of_each_class[current_class_indx]+=1 #increment the pointer\n","\n","        c_name = classes[current_class_indx] # class name\n","        v_name= samples_in_each_class[current_class_indx][i] # video name in class i\n","        video_path = os.path.join(root_dir,c_name,v_name)\n","\n","        # read frames from video ( adjust that to your fast code )\n","        vid = v_name[:-4]\n","        info  = make_dataset(split_file , video_path, mode , vid)\n","        if info:\n","          vid, src, start_frame , nf = info            \n","          total_frames = 64\n","          try:\n","            start_f = random.randint(0, nf - total_frames - 1) + start_frame\n","          except ValueError:\n","            start_f = start_frame\n","          imgs = load_rgb_frames_from_video(video_path, start_f, total_frames)\n","          imgs = padding(imgs , total_frames)\n","          frames = center_crop(imgs)\n","          # yeild the video\n","          yield np.array(frames,dtype=np.float32) ,np.array([int(c_name)],dtype=np.int32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fB62UcAe_-K3","executionInfo":{"status":"ok","timestamp":1623550837635,"user_tz":-120,"elapsed":920405,"user":{"displayName":"deep learning","photoUrl":"","userId":"14472811736176781325"}},"outputId":"716e56e6-c9e0-4c0b-b20f-17f19ee536b7"},"source":["counter = 0\n","i = 0\n","gen = generator_test()\n","for frames ,label in gen:\n","  frames = np.moveaxis(frames,-1,0)\n","  output = tf_rep.run(np.expand_dims(frames,0))\n","  result = np.argmax(np.max(np.array(output),axis=-1))\n","  if result == label:\n","    counter += 1\n","  i+=1\n","print(counter)\n","print(i)\n","print(counter / i)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  if __name__ == '__main__':\n"],"name":"stderr"},{"output_type":"stream","text":["990\n","1264\n","0.7832278481012658\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"daYY43TDtrj4"},"source":[""],"execution_count":null,"outputs":[]}]}